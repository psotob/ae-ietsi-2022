{
  "hash": "756e23595c01572888091458421d7dbf",
  "result": {
    "markdown": "---\ntitle: \"<img data-src='images/logo-essalud.png' height='72' width='250'/> <img data-src='images/logo-pueblo.jpg' height='72' width='250'/> <img data-src='images/logo-ietsi.png' height='72' width='250'/> <FONT color='#232429'><br>Sesión 4</FONT>\"\nsubtitle: \"<FONT color='#636363' size='7'>Programa de Formación Científica:<br>Análisis Estadístico 2022</FONT>\"\nauthor: \"<FONT color='#232429' size='30'>Percy Soto-Becerra</FONT>\"\ninstitute: \"<FONT color='#232429' size='5'>Instituto de Evaluación de Tecnologías en Salud e Investigación - IETSI, EsSalud<br>@github/psotob91</FONT>\"\ndate: \"<FONT color='#232429' size='6'>Julio 1, 2022</FONT>\"\nformat: \n  revealjs: \n    theme: default\n    footer: \"Programa de Formación Científica: Análisis Estadístico 2022 - Sesión 4\"\n    logo: images/logo-ietsi.png\n    transition: convex\n    background-transition: zoom\n    incremental: false\n    slide-number: true\n    preview-links: true\n    # parallax-background-image: images/bg-ietsi-slide-first.png\n    # parallax-background-size: \"1920px 1080px\"\n    chalkboard: true\n    code-block-background: true\n    code-block-border-left: \"#31BAE9\"\n    highlight-style: solarized\n    echo: true\n    multiplex: true\n    touch: true\n    auto-stretch: true\n    link-external-icon: true\n    link-external-newwindow: true\n---\n\n::: {.cell}\n\n:::\n\n\n# Modelo de Regresión Lineal\n\n## Análisis de regresión\n\n![](images/regresion1.png)\n\n## Modelos de regresión multivariable\n\n![](images/regresion2.png)\n\n## ¿Para qué usamos los modelos de regresión?\n\n-   Según `STRATOS` podemos usar regresión para 3 propósitos diferentes:\n\n    -   <FONT size='6'>Descripción\\*</FONT>\n\n    -   <FONT size='6'>Predicción</FONT>\n\n    -   <FONT size='6'>Explicación</FONT>\n\n## Propósitos del modelamiento\n\n![](images/modelos1.png)\n\n::: aside\n<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>\n:::\n\n## Propósitos del modelamiento (cont.)\n\n![](images/modelos2.png)\n\n::: aside\n<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>\n:::\n\n## ¿Para qué usamos los modelos de regresión? (cont.)\n\n-   Este curso se centrará solamente en algunas aplicaciones.\n\n-   Regresión para descripción:\n\n    -   \"Factores asociados..:\" No necesariamente importa que los factores sean causales.\n    -   Evaluación de la magnitud de desigualdades, magnitud de brechas, etc.\n\n## ¿Para qué usamos los modelos de regresión? (cont.) {.scrollable}\n\n-   Regresión para explicación:\n\n    -   \"Efecto / Efectividad / Impacto\": Busca estimar efectos causales.\n    -   Explorar potenciales factores causales... (puede clasificarse dentro de descripción)\n\n-   Regresión para predicción:\n\n    -   Factores pronóstico o predictores de...\": Identifican predictores de interés que luego alimenten mdelos predictivos.\n    -   Modelos de predicción: Predicción para diagnóstico y pronóstico.\n\n## ¿Para qué usamos los modelos de regresión? (cont.)\n\n-   No abordaremos modelos de regresión para desarrollar modelos o reglas de predicción clínica.\n\n-   Tampoco para métodos de inferencia causal robusta.\n\n## Regresión Lineal\n\n-   Método estadístico que modela la `relación` entre una `variable continua (dependiente)` y otras `variables (independientes)`.\n\n![](images/regresion-lineal.png)\n\n## Relación entre dos variables\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n-   $Y$ es `variable resultado` (_outcome_), respuesta o dependiente.\n\n-   $X$ es una `variable explicativa`, predictora o regresora.\n\n-   En la figura, a mayor valor de $X$, mayor valor de $Y$.\n\n\n::: {.cell}\n\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n::::\n\n## ¿Cómo podemos resumir la relación entre ambas variables?\n\n:::: {.columns}\n\n::: {.column width=50%}\n\n- Podemos tratar de dibujar una `línea recta` que `resuma` la relación. \n\n- Existen `infinitas rectas posibles` que podríamos trazar: ¿Cuál elegir?\n\n:::\n::: {.column width=50%}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n## ¿Cómo podemos resumir la relación entre ambas variables? (cont.)\n\n:::: {.columns}\n\n::: {.column width=50%}\n\n- Una opción sería elegir una `recta` que pase por el `valor más representativo` del $y_i$ en cada valor fijo de $x_1$.\n    + Una `recta` que `conecte` los `promedios condicionados` en $x_1$\n\n:::\n::: {.column width=50%}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n## Anatomía de la RLS {.scrollable}\n\n- Entonces, la `recta que conecta los promedios` de $y_i$ `condiciondos` en $x_{1i}$ se puede expresar mediante la siguiente `combinación lineal`:\n\n\n$$\\beta_0 + \\beta_1x_{1i}$$ \n\n\n-   __Componente Sistemático:__ Formalmente hablando, para cada observación $i$ en la población, podemos `relacionar` el `valor esperado` (promedio) $E[y_i]$ de $y_i$ (también llamado $\\mu_i$) con la `variable explicativa` $x_{1i}$ mediante la siguiente `ecuación lineal`:\n\n\n$$E[Y | X_1 = x_{1i}] = E[y_i] =  \\mu_i = \\beta_0 + \\beta_1x_{1i}$$ \n\n\n- Donde:\n    - $y_i$ son `variables aleatorias` independientes e idénticamente distribuidas (`i.i.d`)\n    - $x_1$ es una variable cuyas valores son fijos y conocidos: $x_1i$:\n        + Se asume se `miden sin error`.\n        + `No importa` su `distribución`. \n    - $\\beta_0$ y $\\beta_1$ son `parámetros desconocidos` de una superpoblación infinita.\n        + Llamados `coeficientes de regresión` y son una `medida de asociación`.\n        + Es lo que `queremos estimar` con los datos de la muestra!\n    \n## Anatomía de la RLS (cont.) {.scrollable}\n\n- Notar que el `componente sistemático` solo `relaciona` el `promedio condicionado` de $y_i$ con las `variables explicativas`, NO con los valores individuales. \n\n    + Esta es una manera de obtener una medida que resuma las relaciones individuales en una sola medida. \n\n- __Componente aleatorio:__ Para poder relacionar completamente los valores individuales se agrega un término de error $\\epsilon$, el cual se obtiene de restar el valor observado $y_i$ con el valor esperado de este ($\\mu_i$): \n\n\n$$\\epsilon_i = y_i - \\mu_i$$\n\n\n- El problema es que el término de error $\\epsilon_i$ no puede predecirse ni estimarse con los datos, se considera que es el componente no explicado por estos. \n\n    + Para lidiar con este, se asume que su comportamiento puede predecirse a nivel probabilístico: Se asume una distribución de este.\n    + El error $\\epsilon_i$ hereda la distribución de probabilidad de $y_i$. \n\n- Por lo tanto, el valor individual de cada $y_i$ puede ser denotado por la siguiente expresión:\n\n\n$$y_i = \\beta_0 + \\beta_1x_{1i} + \\epsilon_i$$ \n\n\n- Para hacer inferencia estadística, a menudo se asume lo siguiente:\n\n\n$$y_i \\sim N(\\beta_0 + \\beta_1x_{1i}, \\sigma^2)$$\n\n$$\\epsilon_i \\sim N(0, \\sigma^2) $$\n\n## Regresión Lineal Normal\n\n![](images/regresion-normal.png)\n\n\n## \n\n:::{.callout-note}\n\n### Algunas notas sobre normalidad\n\n- No es necesario que $\\epsilon_i$ o $y_i$ sigan una distribución normal para que los coeficientes de regresión $\\beta$ puedan estimarse de manera puntual. \n\n- Sin embargo, para estimar el `valor p` o los `intervalos de confianza` mediante `inferencia clásica` sí se necesita asumir una distribución conocida. El modelo de regresión lineal normal asume normalidad de estos.\n\n    + Asimismo, el modelo es robusto a desviaciones leves/moderadas de la normalidad cuando se cumple el TLC (número de observaciones grande). \n\n- Otros enfoques para inferencia flexibilizan este supuesto: p. ej., bootstrap, varianza robusta, modelo lineal generalizado que asume otras distribuciones, etc.\n\n:::\n\n## Estimación de ecuación de regresión\n\n- En la práctica no conocemos los valores de los parámetros, así que los estimamos de nuestros datos.\n\n![](images/regresion-parametro-estim.png)\n\n## ¿Cómo estimamos la ecuación lineal que mejor ajusta a los datos observados?\n\n- Usamos métodos numéricos: \n\n    + Método de Mínimos Cuadrados Ordinarios\n    \n    + Método de Máxima Verosimilitud\n    \n- Ambos métodos son equivalentes para el caso de la regresión lineal normal.\n\n## Regresión Lineal Simple sobre variable explicativa categórica\n\n- Las variables categóricas no son continuas, en cambio son discretas y asumen unos cuantos valores.\n\n- ¿Cómo estimar una medida de asociación cuando la variable explicativa es categórica?\n\n\n::: {.cell}\n\n:::\n\n\n## Regresión Lineal Simple sobre variable explicativa categórica\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n## Regresión Lineal Simple sobre variable explicativa categórica (cont.)\n\n - Si la variable es binaria, una forma de abordar el análisis es asignando a una categoría el valor de 1 y a otra el valor de 0.\n\n    + Entonces, asumiremos que la variable categórica es numérica para los efectos de todo cálculo.\n    \n    + Sin embargo, la interpretación se centrará en la comparación de categorías.\n    \n## Regresión Lineal Simple sobre variable explicativa categórica (cont.) \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Regresión Lineal Simple en R {.scrollable}\n\n\n::: {.cell}\n\n:::\n\n\n- Se usa la función `lm()` de R base. Sin embargo, la salida de esta no es muy informativa:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(y ~ x1, data = datos)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1, data = datos)\n\nCoefficients:\n        (Intercept)  x1Tratamiento Nuevo  \n           -0.06666              4.27094  \n```\n:::\n:::\n\n\n- El modelo puede guardarse para realizar más operaciones sobre este. Por ejemplo, mejorar la salida:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(y ~ x1, data = datos)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.8666 -1.1168 -0.3487  1.3100  4.1336 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -0.06666    0.37316  -0.179    0.859    \nx1Tratamiento Nuevo  4.27094    0.52773   8.093 1.59e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.866 on 48 degrees of freedom\nMultiple R-squared:  0.5771,\tAdjusted R-squared:  0.5683 \nF-statistic:  65.5 on 1 and 48 DF,  p-value: 1.594e-10\n```\n:::\n:::\n\n\n## Interpretación de salida de RLS {.scrollable}\n\n::: panel-tabset\n\n### Covariable numérica\n\n- Usamos la función lm():\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(y_peso_final ~ x3_peso_inicial, data = datos2)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y_peso_final ~ x3_peso_inicial, data = datos2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.0568  -4.7717  -0.8704   5.1824  10.4953 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      -5.4317     2.6574  -2.044   0.0412 *  \nx3_peso_inicial   1.3447     0.1766   7.615  6.1e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.535 on 998 degrees of freedom\nMultiple R-squared:  0.05491,\tAdjusted R-squared:  0.05397 \nF-statistic: 57.99 on 1 and 998 DF,  p-value: 6.1e-14\n```\n:::\n:::\n\n\n- El modelo estimado sería el siguiente:\n\n\n$$y\\_pesofinal = -5.4317 + 1.3447*x3\\_pesoinicial + \\epsilon_i$$\n\n$$\\epsilon_i \\sim Normal(0, 5.535^2)$$\n\n\n- Usando el paquete `{broom}` y su función `tidy()` podemos obtener también los intervalos de confianza:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmod %>% \n  tidy(conf.int = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 7\n  term            estimate std.error statistic  p.value conf.low conf.high\n  <chr>              <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)        -5.43     2.66      -2.04 4.12e- 2  -10.6      -0.217\n2 x3_peso_inicial     1.34     0.177      7.62 6.10e-14    0.998     1.69 \n```\n:::\n:::\n\n\n\n- Interpretación:\n\n    + $\\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor. \n    \n    + $\\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.43 kg (IC95% 1.00 a 1.69; p < 0.001). \n\n### Covariable categórica\n\n- Usamos la función lm():\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(y_peso_final ~ x1_tto, data = datos2)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y_peso_final ~ x1_tto, data = datos2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.7043 -1.6644 -0.0095  1.5849  8.5658 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              19.8771     0.1112  178.67   <2e-16 ***\nx1_ttoTratamiento Nuevo -10.2325     0.1573  -65.04   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.488 on 998 degrees of freedom\nMultiple R-squared:  0.8091,\tAdjusted R-squared:  0.8089 \nF-statistic:  4230 on 1 and 998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n- Usando tidy de broom: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% \n  tidy(conf.int = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  <chr>                     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)                19.9     0.111     179.        0     19.7     20.1 \n2 x1_ttoTratamiento Nue…    -10.2     0.157     -65.0       0    -10.5     -9.92\n```\n:::\n:::\n\n\n- Interpretación:\n\n    + $\\beta_0$ (Intercept): A menudo no se interpreta. Es el valor promedio de $y_i$ cuando los valores de $x$ son cero. En este caso, cuando el tratamien es cero (placebo). ¿Esto es posible?, sí es posible pero no es de ayuda para modelos explicativos, por lo que no se interpreta.\n    \n    + $\\beta1$ x1Tratamiento Nuevo: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.23 kg menor que el de quienes recibieron placebo (Dif. medias = -10.23; IC95% -10.54 a -9.92; p < 0.001). \n\n:::\n\n## Regresión Lineal Múltiple {.scrollable}\n\n- Generaliza la RLS permitiendo evaluar la relación de varias covariables explicativas $x$ sobre $y_i$.\n\n- Para $p$ variables explicativas, el modelo puede expresarse como:\n\n**Componente sistemático:**\n\n\n$$E[Y | X_1 = x_{1i}, ..., X_p = x_{pi}] = E[y_i] =  \\mu_i = \\beta_0 + \\beta_1x_{1i} + ... + \\beta_px_{pi}$$ \n\n\n**Componente aleatoria:**\n\n\n$$y_i \\sim N(\\beta_0 + \\beta_1x_{1i} + ... + \\beta_px_{pi}, \\sigma^2)$$\n\n$$\\epsilon_i \\sim N(0, \\sigma^2) $$\n\n\n## Regresión Lineal en gráficos {.scrollable}\n\n::: panel-tabset\n\n### RLS\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- La ecuación de la RLS representa una línea recta.\n\n:::\n\n::: {.column width=\"60%\"}\n\n![](images/regresion-linea.png)\n\n:::\n\n:::: \n\n### RLM con 2 X\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- La ecuación de la RLM con dos variables explicativas ya no representa una línea recta, sino un plano recto.\n\n:::\n\n::: {.column width=\"60%\"}\n\n![](images/regresion-plano.png)\n\n:::\n\n:::: \n\n### RLM con 3 o más X\n\n- Genera un hiperplano recto.\n\n- No podemos imaginarnos una imagen de esto, pero sí podemos analizarlo a nivel estadístico.\n\n:::\n\n## RLM en R {.scrollable}\n\n- Usamos la función lm():\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.5598 -1.4213  0.1343  1.0768  5.4482 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              -0.94719    0.99689   -0.95    0.342    \nx1_ttoTratamiento Nuevo -10.25530    0.13111  -78.22   <2e-16 ***\nx3_peso_inicial           1.38755    0.06614   20.98   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.073 on 997 degrees of freedom\nMultiple R-squared:  0.8676,\tAdjusted R-squared:  0.8673 \nF-statistic:  3266 on 2 and 997 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n- El modelo estimado sería el siguiente:\n\n\n$$y\\_pesofinal = -0.94719 -10.25530*x1ttoTratamientoNuevo + 1.3875*x3\\_pesoinicial + \\epsilon_i$$\n\n$$\\epsilon_i \\sim Normal(0, 2.073^2)$$\n\n\n- Usando el paquete `{broom}` y su función `tidy()` podemos obtener también los intervalos de confianza:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmod %>% \n  tidy(conf.int = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  <chr>                    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)             -0.947    0.997     -0.950 3.42e- 1    -2.90      1.01\n2 x1_ttoTratamiento Nu…  -10.3      0.131    -78.2   0          -10.5     -10.0 \n3 x3_peso_inicial          1.39     0.0661    21.0   3.10e-81     1.26      1.52\n```\n:::\n:::\n\n\n\n- Interpretación:\n\n    + $\\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg y cuando el tratamiento es placebo. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor. \n    \n    + $\\beta_2$ o coeficiente de regresión de `x1_ttoTratamiento Nuevo`: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.26 kg menor que el de quienes recibieron placebo, luego de ajustar por peso inicial (Dif. medias = -10.26; IC95% -10.51 a -9.99; p < 0.001). \n    \n    + $\\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.39 kg, luego de ajustar por tatamiento recibido (IC95% 1.26 a 1.52; p < 0.001). \n\n:::\n\n## Errores y residuos\n\n- Los `errores` ($\\epsilon_i$) son medidas de la población a la que no tenemos acceso.\n\n    + Sin embargo, varios supuestos de la regresión involucran a los errores inaccesibles por el investigador.\n\n- Los `residuos` ($e_i$) son el análogo a los `errores` pero obtenidos de la `muestra observada`.\n\n- Podemos usar los `residuos` para `evaluar` algunos `supuestos` sobre los `errores`. \n\n## Residuos gráficamente\n\n![](images/recta-residuo.png)\n\n## Supuestos de la regresión lineal normal\n\n- Linealidad \n\n- Independencia de observaciones\n\n- Homocedasticidad de los errores $\\epsilon_i$\n\n- Normalidad de los errores $\\epsilon_i$ o de $y_i$.\n\n- No problemas con la regresión:\n\n    + Puntos influyentes.\n    + (Multi) colinealidad: Solo cuando es un problema, no siempre lo es.\n\n\n## {.scrollable}\n\n:::{.callout-note}\n\n### Algunas notas sobre los errores y residuos\n\n- En realidad, los supuestos de los modelos lineales son sobre el comportamiento probabilístico de $y_i$.\n\n- Sin embargo, la idea de la existencia de los `errores` y de sus valores observados en la muestra, `residuos` resulta útil para evaluar supuestos.\n\n    + Permiten reducir un problema de muchas dimensiones a solo 1 o 2 dimensiones.\n    \n    + Son como las placas radiográficas para el diagnóstico de los modelos.\n    \n![](images/residuos-placa.png)\n\n:::\n\n## ¿Cómo evaluar los supuestos de la regresión lineal? {.scrollable}\n\n- Se usan los residuos para explorar el comportamiento de los $y_i$ o los errores $\\epsilon$.\n\n- Preferiblemente usar gráficos de residuos.\n\n    + Pruebas de hipótesis que usan residuos tienen los mismos problemas que discutimos en clases anteriores.\n    \n    + Podríamos usarlas para complementar análisis cuando los tamaños de muestra no son ni muy pequeños ni muy grandes.\n\n- La función `check_model` del paquete `{performance}` genera un panel de gráficos muy útil para evalur estos supuestos.\n\n- Podemos complentar el análisis de supuestos con funciones del paquete `{car}`.\n\n::: panel-tabset\n\n### Panel general\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_model(mod)\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n### Lin. det.\n\n- Podemos usar gráficos de residuos parciales + Componente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\ncrPlots(mod)\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n- También podemos usar gráficos de variable agregada\n\n\n::: {.cell}\n\n```{.r .cell-code}\navPlots(mod)\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n### Homo. det.\n\n- Se puede evaluar si la homocedasticidad es consistente según cada variable predictora.\n\n- Si no lo es, se puede optar por modelar esta heterogeneidad de varianzas.\n\n- Se sugiere usar `residuos estudentizados`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresidualPlots(mod, type = \"rstudent\")\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-23-1.png){width=960}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                Test stat Pr(>|Test stat|)\nx1_tto                                    \nx3_peso_inicial    1.2180           0.2235\nTukey test         0.5429           0.5872\n```\n:::\n:::\n\n\n\n### P. inf. det.\n\n- En el caso de modelos explicativos, importa determinar si hay un impacto en los coeficientes de regresion.\n\n- Los `dfbetas` pueden ser útiles para evaluar esto:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndfbetasPlots(model = mod, id.n = 5)\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-24-1.png){width=960}\n:::\n:::\n\n\n- Otras medidas también pueden evaluarse:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninfluenceIndexPlot(model = mod, id.n = 5)\n```\n\n::: {.cell-output-display}\n![](Sesion-4_files/figure-revealjs/unnamed-chunk-25-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n\n## Tablas de regresión lineal reproducible {.scrollable}\n\n- Podemos usar la librería {gtsummary} para esto.\n\n- Veamos un ejemplo.\n\n##\n\n::: r-fit-text\n<br>\n\n<center>\n\nslides:\n\n</center>\n\n<center>\n\n[https://bit.ly/3n6Ejzb](https://ietsi-academy-aed.netlify.app/sesiones/sesion-1/sesion-1c)\n\n</center>\n:::\n\n## \n\n::: r-fit-text\n<center>**¡Gracias por su atención!**</center>\n\n<center>**¡Encantado de responder sus consultas!**</center>\n\n<br>\n\n<center>**Percy Soto-Becerra**</center>\n\n<br>\n\n<center><svg viewBox=\"0 0 512 512\" style=\"height:1em;position:relative;display:inline-block;top:.1em;\" xmlns=\"http://www.w3.org/2000/svg\">  <path d=\"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z\"></path></svg> <svg viewBox=\"0 0 496 512\" style=\"height:1em;position:relative;display:inline-block;top:.1em;\" xmlns=\"http://www.w3.org/2000/svg\">  <path d=\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\"></path></svg> @psotob91</center>\n\n<center><svg viewBox=\"0 0 576 512\" style=\"height:1em;position:relative;display:inline-block;top:.1em;\" xmlns=\"http://www.w3.org/2000/svg\">  <path d=\"M567.938 243.908L462.25 85.374A48.003 48.003 0 0 0 422.311 64H153.689a48 48 0 0 0-39.938 21.374L8.062 243.908A47.994 47.994 0 0 0 0 270.533V400c0 26.51 21.49 48 48 48h480c26.51 0 48-21.49 48-48V270.533a47.994 47.994 0 0 0-8.062-26.625zM162.252 128h251.497l85.333 128H376l-32 64H232l-32-64H76.918l85.334-128z\"></path></svg> **percys1991\\@gmail.com**</center>\n\n:::\n\n::: aside\n<br> <FONT size='4'>Presentación creada vía `Revealjs` en `Quarto` en `RStudio`.</FONT>\n:::\n",
    "supporting": [
      "Sesion-4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}